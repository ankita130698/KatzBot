{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97e71e6",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0337a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from rouge import Rouge\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e74f29",
   "metadata": {},
   "source": [
    "# Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22cf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        # load train dataset\n",
    "        self.dataset_dir = r\"D:\\Yeshiva\\Spring24\\AI\\katzbot\"\n",
    "        \n",
    "        self.train_path = r\"dataset_katzbot/New_Train_QA_Pairs.csv\"\n",
    "        self.input_file_path = os.path.join(self.dataset_dir, self.train_path)\n",
    "        \n",
    "        # load test dataset\n",
    "        self.test_path = r\"dataset_katzbot/Test_QA_Pairs.csv\"\n",
    "        self.test_data = os.path.join(self.dataset_dir, self.test_path)\n",
    "        self.save_text_file = \"predicted_answer.txt\"\n",
    "        self.save_text_file_rlhf = \"predicted_answer_rlhf.txt\"\n",
    "        self.predict_file = \"Test_QA_Pairs_pretrained_gpt.csv\"\n",
    "        self.eval_results = \"eval_results.csv\"\n",
    "        self.clf_data = \"clf_dataset.csv\"\n",
    "        \n",
    "        self.original_text = \"answer\"\n",
    "        self.predicted_result = \"predicted_answer\"\n",
    "        self.predicted_result_2 = \"predicted_answer_2\"\n",
    "\n",
    "        \n",
    "        # list of gpt model \n",
    "        self.gpt_model = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\"]\n",
    "        self.gpt = self.gpt_model[0]\n",
    "        # # Model and tokeniser\n",
    "        self.model_type = self.gpt\n",
    "        self.tokenizer_name = self.gpt\n",
    "        \n",
    "        # Sets the directory to which the trained model will be saved\n",
    "        self.output_dir = 'models_pretrained_4'\n",
    "        self.model_name = \"pretrained_gpt2.pt\"\n",
    "\n",
    "        # rlhf model\n",
    "        self.model_rlhf_name = 'bert-base-uncased'\n",
    "        \n",
    "        \n",
    "        # Parameters\n",
    "        # Set the seed value all over the place to make this reproducible.\n",
    "        self.seed_val = 42\n",
    "        self.batch_size = 4\n",
    "        self.epochs = 60\n",
    "        self.learning_rate = 5e-4\n",
    "        self.warmup_steps = 1e2\n",
    "        self.epsilon = 1e-5\n",
    "        self.weight_decay = 1e-2\n",
    "        self.sample_every = 100\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "        # bert ppo\n",
    "        self.N_GPUS = 1\n",
    "        self.TRAIN_EPOCHS = 2\n",
    "        self.TRAIN_BATCH_SIZE = 8\n",
    "        self.EVAL_BATCH_SIZE = 8\n",
    "        self.MAX_LEN = 128\n",
    "        self.LOGGING_STEPS = 64\n",
    "        self.SAVE_STEPS = 10240  # reduce it to a smaler value like 512 if you want to save checkpoints\n",
    "        self.SAVE_TOTAL_LIMIT = 2\n",
    "\n",
    "        self.set_seed = 123\n",
    "        \n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e02905d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import BertTokenizerFast\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from transformers import set_seed\n",
    "from transformers import Trainer\n",
    "from datasets import DatasetDict\n",
    "import transformers\n",
    "import numpy as np\n",
    "import datasets\n",
    "import logging \n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293aad8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "752770d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d10c7b281b44a69142c6473005d90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahil\\.conda\\envs\\genai\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sahil\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc237ca79634a48809b9013258be166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916ee1a64a024f519f35d4c1ea849cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# creates an instance of the BertForSequenceClassification class from the Hugging Face Transformers library.\n",
    "model_bert = BertForSequenceClassification.from_pretrained(args.model_rlhf_name, num_labels=2,  force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be18dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(args.model_rlhf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33014d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models_pretrained_4\\\\clf_dataset.csv'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8c00d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3f82591be14082a2477036ea3315f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee14b82a108400194d672bacfbeff3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3538ab8fa93d493f8d3d0e826835a2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "from transformers import BertTokenizerFast\n",
    "import os\n",
    "import functools\n",
    "\n",
    "# # Define your tokenizer\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Define your preprocess function\n",
    "# def preprocess_function(examples, tokenizer):\n",
    "#     return tokenizer(examples['response'], truncation=True, padding=True)\n",
    "\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    # Extract response text from examples\n",
    "    responses = examples['response']\n",
    "    \n",
    "    # Encode the response text using tokenizer.batch_encode_plus\n",
    "    encodings = tokenizer.batch_encode_plus(\n",
    "        responses,  # List of response texts\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Return the encoded inputs\n",
    "    return encodings\n",
    "\n",
    "# Load your dataset\n",
    "data = load_dataset('csv', \n",
    "                    data_files=test_clf, \n",
    "                    delimiter=',', \n",
    "                    split='train', \n",
    "                    cache_dir='/tmp/cache')\n",
    "\n",
    "# Split your dataset\n",
    "train_validation_test = data.train_test_split(shuffle=True, seed=123, test_size=0.1)\n",
    "data_splits = DatasetDict({'train': train_validation_test['train'],  \n",
    "                           'validation': train_validation_test['test']})\n",
    "\n",
    "# Partially apply the tokenizer to the preprocess function\n",
    "partial_preprocess_function = functools.partial(preprocess_function, tokenizer=tokenizer)\n",
    "\n",
    "# Tokenize datasets \n",
    "num_proc = int(os.cpu_count()/args.N_GPUS)\n",
    "tokenized_data = data_splits.map(partial_preprocess_function, \n",
    "                                 batched=True, \n",
    "                                 num_proc=num_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a332306",
   "metadata": {},
   "source": [
    "# Finetune\n",
    "Define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a77fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set various training parameters such as the number of training epochs, batch size, and logging options.\n",
    "training_args = TrainingArguments(output_dir=args.output_dir + '/train', \n",
    "                                  overwrite_output_dir=True, \n",
    "                                  num_train_epochs=args.epochs,  \n",
    "                                  optim='adamw_torch', \n",
    "                                  save_strategy='steps', \n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  per_device_train_batch_size=args.TRAIN_BATCH_SIZE, \n",
    "                                  per_device_eval_batch_size=args.EVAL_BATCH_SIZE, \n",
    "                                  warmup_steps=args.warmup_steps, \n",
    "                                  weight_decay=args.weight_decay,\n",
    "                                  logging_steps=args.LOGGING_STEPS,\n",
    "                                  save_steps=args.SAVE_STEPS, \n",
    "                                  save_total_limit=args.SAVE_TOTAL_LIMIT,\n",
    "                                  logging_dir='logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f09d5",
   "metadata": {},
   "source": [
    "### Training\n",
    "P.S: Since our dataset is small it has overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2472397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahil\\.conda\\envs\\genai\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahilkumar158\u001b[0m (\u001b[33msahilthegnius\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Yeshiva\\Spring24\\AI\\katzbot_6\\wandb\\run-20240504_154821-33284civ</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sahilthegnius/huggingface/runs/33284civ' target=\"_blank\">scruffy-looking-astromech-9</a></strong> to <a href='https://wandb.ai/sahilthegnius/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sahilthegnius/huggingface' target=\"_blank\">https://wandb.ai/sahilthegnius/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sahilthegnius/huggingface/runs/33284civ' target=\"_blank\">https://wandb.ai/sahilthegnius/huggingface/runs/33284civ</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591e4b1b82f84f74897dc99423cdb5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.713, 'grad_norm': 9.705682754516602, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.19}\n",
      "{'loss': 0.6098, 'grad_norm': 4.184609413146973, 'learning_rate': 4.993062438057483e-05, 'epoch': 0.38}\n",
      "{'loss': 0.643, 'grad_norm': 7.928568363189697, 'learning_rate': 4.977205153617443e-05, 'epoch': 0.57}\n",
      "{'loss': 0.6194, 'grad_norm': 8.016056060791016, 'learning_rate': 4.961347869177403e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6349, 'grad_norm': 7.96769380569458, 'learning_rate': 4.945490584737364e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e134083c3b498fabf83aa7ca7034d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.585211455821991, 'eval_runtime': 0.4738, 'eval_samples_per_second': 635.263, 'eval_steps_per_second': 80.199, 'epoch': 1.0}\n",
      "{'loss': 0.6263, 'grad_norm': 5.150811195373535, 'learning_rate': 4.929633300297324e-05, 'epoch': 1.14}\n",
      "{'loss': 0.6139, 'grad_norm': 3.554089069366455, 'learning_rate': 4.913776015857285e-05, 'epoch': 1.33}\n",
      "{'loss': 0.5955, 'grad_norm': 8.724480628967285, 'learning_rate': 4.8979187314172446e-05, 'epoch': 1.51}\n",
      "{'loss': 0.6038, 'grad_norm': 5.327426910400391, 'learning_rate': 4.882061446977205e-05, 'epoch': 1.7}\n",
      "{'loss': 0.6136, 'grad_norm': 4.9745306968688965, 'learning_rate': 4.866204162537166e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e8f3b85ac24b41874bf674aca54b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5983776450157166, 'eval_runtime': 0.4231, 'eval_samples_per_second': 711.333, 'eval_steps_per_second': 89.803, 'epoch': 2.0}\n",
      "{'loss': 0.6255, 'grad_norm': 3.9734127521514893, 'learning_rate': 4.850346878097126e-05, 'epoch': 2.08}\n",
      "{'loss': 0.5794, 'grad_norm': 2.347931146621704, 'learning_rate': 4.834489593657087e-05, 'epoch': 2.27}\n",
      "{'loss': 0.6012, 'grad_norm': 7.1977081298828125, 'learning_rate': 4.8186323092170465e-05, 'epoch': 2.46}\n",
      "{'loss': 0.5894, 'grad_norm': 5.887740612030029, 'learning_rate': 4.802775024777007e-05, 'epoch': 2.65}\n",
      "{'loss': 0.585, 'grad_norm': 5.098109722137451, 'learning_rate': 4.7869177403369676e-05, 'epoch': 2.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5875021b2efb412ab2c4831b6ab3c3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5981137156486511, 'eval_runtime': 0.4238, 'eval_samples_per_second': 710.317, 'eval_steps_per_second': 89.675, 'epoch': 3.0}\n",
      "{'loss': 0.5827, 'grad_norm': 6.896564483642578, 'learning_rate': 4.771060455896928e-05, 'epoch': 3.03}\n",
      "{'loss': 0.5304, 'grad_norm': 6.214574813842773, 'learning_rate': 4.7552031714568886e-05, 'epoch': 3.22}\n",
      "{'loss': 0.4889, 'grad_norm': 2.8115968704223633, 'learning_rate': 4.7393458870168485e-05, 'epoch': 3.41}\n",
      "{'loss': 0.5389, 'grad_norm': 6.403600692749023, 'learning_rate': 4.723488602576809e-05, 'epoch': 3.6}\n",
      "{'loss': 0.5232, 'grad_norm': 7.21414041519165, 'learning_rate': 4.7076313181367695e-05, 'epoch': 3.79}\n",
      "{'loss': 0.5517, 'grad_norm': 6.620140075683594, 'learning_rate': 4.69177403369673e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37acc665aba3489eaf1a88635b2009d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6047483682632446, 'eval_runtime': 0.4371, 'eval_samples_per_second': 688.553, 'eval_steps_per_second': 86.927, 'epoch': 4.0}\n",
      "{'loss': 0.4409, 'grad_norm': 3.3323092460632324, 'learning_rate': 4.6759167492566905e-05, 'epoch': 4.17}\n",
      "{'loss': 0.4129, 'grad_norm': 7.922998428344727, 'learning_rate': 4.6600594648166504e-05, 'epoch': 4.36}\n",
      "{'loss': 0.4643, 'grad_norm': 3.903552532196045, 'learning_rate': 4.644202180376611e-05, 'epoch': 4.54}\n",
      "{'loss': 0.4973, 'grad_norm': 3.665043830871582, 'learning_rate': 4.628344895936571e-05, 'epoch': 4.73}\n",
      "{'loss': 0.429, 'grad_norm': 2.2300140857696533, 'learning_rate': 4.612487611496531e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ab38997324482eb4d4e785b2348368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7799862623214722, 'eval_runtime': 0.4252, 'eval_samples_per_second': 707.957, 'eval_steps_per_second': 89.377, 'epoch': 5.0}\n",
      "{'loss': 0.4157, 'grad_norm': 4.0540852546691895, 'learning_rate': 4.596630327056492e-05, 'epoch': 5.11}\n",
      "{'loss': 0.4128, 'grad_norm': 3.31119966506958, 'learning_rate': 4.5807730426164516e-05, 'epoch': 5.3}\n",
      "{'loss': 0.3708, 'grad_norm': 7.786618232727051, 'learning_rate': 4.564915758176412e-05, 'epoch': 5.49}\n",
      "{'loss': 0.4102, 'grad_norm': 19.939044952392578, 'learning_rate': 4.5490584737363726e-05, 'epoch': 5.68}\n",
      "{'loss': 0.3962, 'grad_norm': 5.385005950927734, 'learning_rate': 4.533201189296333e-05, 'epoch': 5.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcbb68789e3456ebad378f97be22793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7896427512168884, 'eval_runtime': 0.4446, 'eval_samples_per_second': 677.06, 'eval_steps_per_second': 85.476, 'epoch': 6.0}\n",
      "{'loss': 0.3863, 'grad_norm': 4.1749796867370605, 'learning_rate': 4.517343904856294e-05, 'epoch': 6.06}\n",
      "{'loss': 0.3894, 'grad_norm': 2.8217318058013916, 'learning_rate': 4.5014866204162535e-05, 'epoch': 6.25}\n",
      "{'loss': 0.3201, 'grad_norm': 6.703165531158447, 'learning_rate': 4.485629335976214e-05, 'epoch': 6.44}\n",
      "{'loss': 0.3488, 'grad_norm': 25.658218383789062, 'learning_rate': 4.4697720515361746e-05, 'epoch': 6.63}\n",
      "{'loss': 0.3652, 'grad_norm': 3.930603265762329, 'learning_rate': 4.453914767096135e-05, 'epoch': 6.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2abe305e01436793c9151ebd60c2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1547133922576904, 'eval_runtime': 0.4245, 'eval_samples_per_second': 709.15, 'eval_steps_per_second': 89.527, 'epoch': 7.0}\n",
      "{'loss': 0.3686, 'grad_norm': 15.32899284362793, 'learning_rate': 4.4380574826560956e-05, 'epoch': 7.01}\n",
      "{'loss': 0.3484, 'grad_norm': 31.668201446533203, 'learning_rate': 4.4222001982160554e-05, 'epoch': 7.2}\n",
      "{'loss': 0.2854, 'grad_norm': 54.9526252746582, 'learning_rate': 4.406342913776016e-05, 'epoch': 7.38}\n",
      "{'loss': 0.3098, 'grad_norm': 13.56691837310791, 'learning_rate': 4.3904856293359765e-05, 'epoch': 7.57}\n",
      "{'loss': 0.3396, 'grad_norm': 0.6195231080055237, 'learning_rate': 4.374628344895937e-05, 'epoch': 7.76}\n",
      "{'loss': 0.2861, 'grad_norm': 4.015673637390137, 'learning_rate': 4.3587710604558975e-05, 'epoch': 7.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4188f955399340e18146d10034380f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4005240201950073, 'eval_runtime': 0.4339, 'eval_samples_per_second': 693.632, 'eval_steps_per_second': 87.568, 'epoch': 8.0}\n",
      "{'loss': 0.2906, 'grad_norm': 0.8239462971687317, 'learning_rate': 4.3429137760158573e-05, 'epoch': 8.14}\n",
      "{'loss': 0.2944, 'grad_norm': 135.0910186767578, 'learning_rate': 4.327056491575818e-05, 'epoch': 8.33}\n",
      "{'loss': 0.2849, 'grad_norm': 0.48681360483169556, 'learning_rate': 4.3111992071357784e-05, 'epoch': 8.52}\n",
      "{'loss': 0.2982, 'grad_norm': 1.6736161708831787, 'learning_rate': 4.295341922695739e-05, 'epoch': 8.71}\n",
      "{'loss': 0.3351, 'grad_norm': 4.008373260498047, 'learning_rate': 4.2794846382556994e-05, 'epoch': 8.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d45d95e1cdb4e4ba655d7883cbe2d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2881274223327637, 'eval_runtime': 0.4312, 'eval_samples_per_second': 697.975, 'eval_steps_per_second': 88.117, 'epoch': 9.0}\n",
      "{'loss': 0.2398, 'grad_norm': 4.732666492462158, 'learning_rate': 4.263627353815659e-05, 'epoch': 9.09}\n",
      "{'loss': 0.2709, 'grad_norm': 9.227558135986328, 'learning_rate': 4.24777006937562e-05, 'epoch': 9.28}\n",
      "{'loss': 0.2752, 'grad_norm': 1.1444370746612549, 'learning_rate': 4.23191278493558e-05, 'epoch': 9.47}\n",
      "{'loss': 0.2729, 'grad_norm': 0.17180711030960083, 'learning_rate': 4.21605550049554e-05, 'epoch': 9.66}\n",
      "{'loss': 0.2746, 'grad_norm': 0.5859779119491577, 'learning_rate': 4.2001982160555007e-05, 'epoch': 9.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62b00c9a52f496ba0f077da9b9ec14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6152454614639282, 'eval_runtime': 0.4253, 'eval_samples_per_second': 707.795, 'eval_steps_per_second': 89.356, 'epoch': 10.0}\n",
      "{'loss': 0.261, 'grad_norm': 20.31339454650879, 'learning_rate': 4.1843409316154605e-05, 'epoch': 10.04}\n",
      "{'loss': 0.2133, 'grad_norm': 0.8393077254295349, 'learning_rate': 4.168483647175421e-05, 'epoch': 10.22}\n",
      "{'loss': 0.2294, 'grad_norm': 0.24358783662319183, 'learning_rate': 4.1526263627353815e-05, 'epoch': 10.41}\n",
      "{'loss': 0.3079, 'grad_norm': 1.7074075937271118, 'learning_rate': 4.136769078295342e-05, 'epoch': 10.6}\n",
      "{'loss': 0.2608, 'grad_norm': 0.21637435257434845, 'learning_rate': 4.1209117938553026e-05, 'epoch': 10.79}\n",
      "{'loss': 0.1548, 'grad_norm': 0.1790114790201187, 'learning_rate': 4.1050545094152624e-05, 'epoch': 10.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee9b1a2563641939841c1c090f63d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.062260627746582, 'eval_runtime': 0.4357, 'eval_samples_per_second': 690.885, 'eval_steps_per_second': 87.221, 'epoch': 11.0}\n",
      "{'loss': 0.1898, 'grad_norm': 0.34586429595947266, 'learning_rate': 4.089197224975223e-05, 'epoch': 11.17}\n",
      "{'loss': 0.1753, 'grad_norm': 96.50180053710938, 'learning_rate': 4.0733399405351834e-05, 'epoch': 11.36}\n",
      "{'loss': 0.1211, 'grad_norm': 0.06657818704843521, 'learning_rate': 4.057482656095144e-05, 'epoch': 11.55}\n",
      "{'loss': 0.225, 'grad_norm': 0.4345085918903351, 'learning_rate': 4.0416253716551045e-05, 'epoch': 11.74}\n",
      "{'loss': 0.2424, 'grad_norm': 18.281959533691406, 'learning_rate': 4.025768087215064e-05, 'epoch': 11.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb5aa75aea0416d917b3ac081907550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7479170560836792, 'eval_runtime': 0.4465, 'eval_samples_per_second': 674.192, 'eval_steps_per_second': 85.114, 'epoch': 12.0}\n",
      "{'loss': 0.1779, 'grad_norm': 51.394893646240234, 'learning_rate': 4.009910802775025e-05, 'epoch': 12.12}\n",
      "{'loss': 0.1714, 'grad_norm': 21.14249038696289, 'learning_rate': 3.9940535183349854e-05, 'epoch': 12.31}\n",
      "{'loss': 0.193, 'grad_norm': 0.20247197151184082, 'learning_rate': 3.978196233894946e-05, 'epoch': 12.5}\n",
      "{'loss': 0.1883, 'grad_norm': 1.0074125528335571, 'learning_rate': 3.9623389494549064e-05, 'epoch': 12.69}\n",
      "{'loss': 0.158, 'grad_norm': 0.12791375815868378, 'learning_rate': 3.946481665014866e-05, 'epoch': 12.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c642a66ec01c4238b2c6e174c703726c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0990593433380127, 'eval_runtime': 0.4309, 'eval_samples_per_second': 698.495, 'eval_steps_per_second': 88.182, 'epoch': 13.0}\n",
      "{'loss': 0.143, 'grad_norm': 19.611087799072266, 'learning_rate': 3.930624380574827e-05, 'epoch': 13.07}\n",
      "{'loss': 0.1315, 'grad_norm': 0.7427903413772583, 'learning_rate': 3.914767096134787e-05, 'epoch': 13.25}\n",
      "{'loss': 0.1396, 'grad_norm': 0.2926842272281647, 'learning_rate': 3.898909811694748e-05, 'epoch': 13.44}\n",
      "{'loss': 0.1289, 'grad_norm': 0.04663185402750969, 'learning_rate': 3.883052527254708e-05, 'epoch': 13.63}\n",
      "{'loss': 0.1478, 'grad_norm': 0.09026261419057846, 'learning_rate': 3.867195242814668e-05, 'epoch': 13.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a2b7e4108e4c3bbeb4e983ae253565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.769930124282837, 'eval_runtime': 0.5, 'eval_samples_per_second': 602.04, 'eval_steps_per_second': 76.005, 'epoch': 14.0}\n",
      "{'loss': 0.174, 'grad_norm': 0.37969970703125, 'learning_rate': 3.8513379583746287e-05, 'epoch': 14.01}\n",
      "{'loss': 0.0397, 'grad_norm': 0.03833344578742981, 'learning_rate': 3.835480673934589e-05, 'epoch': 14.2}\n",
      "{'loss': 0.1948, 'grad_norm': 4.5151495933532715, 'learning_rate': 3.819623389494549e-05, 'epoch': 14.39}\n",
      "{'loss': 0.096, 'grad_norm': 0.09287407249212265, 'learning_rate': 3.8037661050545095e-05, 'epoch': 14.58}\n",
      "{'loss': 0.0985, 'grad_norm': 0.077538400888443, 'learning_rate': 3.78790882061447e-05, 'epoch': 14.77}\n",
      "{'loss': 0.1515, 'grad_norm': 26.28923988342285, 'learning_rate': 3.77205153617443e-05, 'epoch': 14.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d8ede99bcd40039f669d0ce5593c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1375174522399902, 'eval_runtime': 0.457, 'eval_samples_per_second': 658.609, 'eval_steps_per_second': 83.147, 'epoch': 15.0}\n",
      "{'loss': 0.096, 'grad_norm': 0.08287636190652847, 'learning_rate': 3.7561942517343904e-05, 'epoch': 15.15}\n",
      "{'loss': 0.0896, 'grad_norm': 0.06445395946502686, 'learning_rate': 3.740336967294351e-05, 'epoch': 15.34}\n",
      "{'loss': 0.1638, 'grad_norm': 0.12247686833143234, 'learning_rate': 3.7244796828543114e-05, 'epoch': 15.53}\n",
      "{'loss': 0.1717, 'grad_norm': 0.2600786089897156, 'learning_rate': 3.708622398414271e-05, 'epoch': 15.72}\n",
      "{'loss': 0.1391, 'grad_norm': 4.851949214935303, 'learning_rate': 3.692765113974232e-05, 'epoch': 15.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b086d0e54d94461bd8f4ee945ba7348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.22733473777771, 'eval_runtime': 0.483, 'eval_samples_per_second': 623.23, 'eval_steps_per_second': 78.68, 'epoch': 16.0}\n",
      "{'loss': 0.0872, 'grad_norm': 0.9927597045898438, 'learning_rate': 3.676907829534192e-05, 'epoch': 16.09}\n",
      "{'loss': 0.1236, 'grad_norm': 0.05614040419459343, 'learning_rate': 3.661050545094153e-05, 'epoch': 16.28}\n",
      "{'loss': 0.1318, 'grad_norm': 0.23997700214385986, 'learning_rate': 3.6451932606541134e-05, 'epoch': 16.47}\n",
      "{'loss': 0.1029, 'grad_norm': 0.05387008935213089, 'learning_rate': 3.629335976214073e-05, 'epoch': 16.66}\n",
      "{'loss': 0.1622, 'grad_norm': 0.13504785299301147, 'learning_rate': 3.613478691774034e-05, 'epoch': 16.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f1cfd9393940d9ab4d917fe7ebe5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.02226185798645, 'eval_runtime': 0.4716, 'eval_samples_per_second': 638.282, 'eval_steps_per_second': 80.58, 'epoch': 17.0}\n",
      "{'loss': 0.1072, 'grad_norm': 0.11534450948238373, 'learning_rate': 3.597621407333994e-05, 'epoch': 17.04}\n",
      "{'loss': 0.0807, 'grad_norm': 0.04948927462100983, 'learning_rate': 3.581764122893955e-05, 'epoch': 17.23}\n",
      "{'loss': 0.122, 'grad_norm': 5.651455879211426, 'learning_rate': 3.565906838453915e-05, 'epoch': 17.42}\n",
      "{'loss': 0.1591, 'grad_norm': 1.9651844501495361, 'learning_rate': 3.550049554013875e-05, 'epoch': 17.61}\n",
      "{'loss': 0.1066, 'grad_norm': 140.28619384765625, 'learning_rate': 3.5341922695738356e-05, 'epoch': 17.8}\n",
      "{'loss': 0.102, 'grad_norm': 0.0281894039362669, 'learning_rate': 3.518334985133796e-05, 'epoch': 17.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a914450ed14dec8bd961b60aeef6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.575641632080078, 'eval_runtime': 0.4713, 'eval_samples_per_second': 638.653, 'eval_steps_per_second': 80.627, 'epoch': 18.0}\n",
      "{'loss': 0.0952, 'grad_norm': 0.6202699542045593, 'learning_rate': 3.502477700693757e-05, 'epoch': 18.18}\n",
      "{'loss': 0.0768, 'grad_norm': 0.04741666838526726, 'learning_rate': 3.486620416253717e-05, 'epoch': 18.37}\n",
      "{'loss': 0.0582, 'grad_norm': 0.020848125219345093, 'learning_rate': 3.470763131813677e-05, 'epoch': 18.56}\n",
      "{'loss': 0.0692, 'grad_norm': 0.04622381553053856, 'learning_rate': 3.4549058473736375e-05, 'epoch': 18.75}\n",
      "{'loss': 0.0689, 'grad_norm': 0.036981865763664246, 'learning_rate': 3.439048562933598e-05, 'epoch': 18.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae12c4823b643e7aea0e889334ce72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.476820945739746, 'eval_runtime': 0.4562, 'eval_samples_per_second': 659.74, 'eval_steps_per_second': 83.289, 'epoch': 19.0}\n",
      "{'loss': 0.0463, 'grad_norm': 6.632179260253906, 'learning_rate': 3.4231912784935586e-05, 'epoch': 19.12}\n",
      "{'loss': 0.0315, 'grad_norm': 0.01873687468469143, 'learning_rate': 3.4073339940535184e-05, 'epoch': 19.31}\n",
      "{'loss': 0.1184, 'grad_norm': 0.17596419155597687, 'learning_rate': 3.391476709613479e-05, 'epoch': 19.5}\n",
      "{'loss': 0.0665, 'grad_norm': 486.5277099609375, 'learning_rate': 3.375619425173439e-05, 'epoch': 19.69}\n",
      "{'loss': 0.155, 'grad_norm': 0.12435895949602127, 'learning_rate': 3.359762140733399e-05, 'epoch': 19.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b160bf52584e3c8fe5a27503ac7252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4989869594573975, 'eval_runtime': 0.4754, 'eval_samples_per_second': 633.149, 'eval_steps_per_second': 79.932, 'epoch': 20.0}\n",
      "{'loss': 0.0649, 'grad_norm': 0.035739049315452576, 'learning_rate': 3.34390485629336e-05, 'epoch': 20.07}\n",
      "{'loss': 0.1033, 'grad_norm': 0.06355224549770355, 'learning_rate': 3.32804757185332e-05, 'epoch': 20.26}\n",
      "{'loss': 0.0632, 'grad_norm': 0.03630831465125084, 'learning_rate': 3.31219028741328e-05, 'epoch': 20.45}\n",
      "{'loss': 0.0997, 'grad_norm': 0.06563295423984528, 'learning_rate': 3.296333002973241e-05, 'epoch': 20.64}\n",
      "{'loss': 0.0894, 'grad_norm': 0.06527012586593628, 'learning_rate': 3.280475718533201e-05, 'epoch': 20.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c2f508a41a48428efa664f7c777d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3102355003356934, 'eval_runtime': 0.4594, 'eval_samples_per_second': 655.203, 'eval_steps_per_second': 82.717, 'epoch': 21.0}\n",
      "{'loss': 0.0505, 'grad_norm': 0.03581929951906204, 'learning_rate': 3.264618434093162e-05, 'epoch': 21.02}\n",
      "{'loss': 0.0544, 'grad_norm': 0.023096226155757904, 'learning_rate': 3.248761149653122e-05, 'epoch': 21.21}\n",
      "{'loss': 0.0491, 'grad_norm': 0.04009570553898811, 'learning_rate': 3.232903865213082e-05, 'epoch': 21.4}\n",
      "{'loss': 0.0969, 'grad_norm': 0.025570297613739967, 'learning_rate': 3.2170465807730426e-05, 'epoch': 21.59}\n",
      "{'loss': 0.1612, 'grad_norm': 0.16603054106235504, 'learning_rate': 3.201189296333003e-05, 'epoch': 21.78}\n",
      "{'loss': 0.1065, 'grad_norm': 0.09595751762390137, 'learning_rate': 3.1853320118929636e-05, 'epoch': 21.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c67790f78e24316b6a4cb0c8eba239d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1429026126861572, 'eval_runtime': 0.4773, 'eval_samples_per_second': 630.605, 'eval_steps_per_second': 79.611, 'epoch': 22.0}\n",
      "{'loss': 0.0799, 'grad_norm': 0.08568313717842102, 'learning_rate': 3.169474727452924e-05, 'epoch': 22.15}\n",
      "{'loss': 0.0722, 'grad_norm': 43.476112365722656, 'learning_rate': 3.153617443012884e-05, 'epoch': 22.34}\n",
      "{'loss': 0.0974, 'grad_norm': 0.06253413110971451, 'learning_rate': 3.1377601585728445e-05, 'epoch': 22.53}\n",
      "{'loss': 0.0654, 'grad_norm': 0.04272221773862839, 'learning_rate': 3.121902874132805e-05, 'epoch': 22.72}\n",
      "{'loss': 0.0522, 'grad_norm': 0.03318212181329727, 'learning_rate': 3.1060455896927656e-05, 'epoch': 22.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc6ee8990294c3dac7734eda35622e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.184443473815918, 'eval_runtime': 0.4661, 'eval_samples_per_second': 645.752, 'eval_steps_per_second': 81.524, 'epoch': 23.0}\n",
      "{'loss': 0.0961, 'grad_norm': 12.307761192321777, 'learning_rate': 3.090188305252726e-05, 'epoch': 23.1}\n",
      "{'loss': 0.0757, 'grad_norm': 0.056031741201877594, 'learning_rate': 3.074331020812686e-05, 'epoch': 23.29}\n",
      "{'loss': 0.0408, 'grad_norm': 0.035610344260931015, 'learning_rate': 3.0584737363726464e-05, 'epoch': 23.48}\n",
      "{'loss': 0.0918, 'grad_norm': 0.040153343230485916, 'learning_rate': 3.0426164519326066e-05, 'epoch': 23.67}\n",
      "{'loss': 0.0484, 'grad_norm': 0.019803769886493683, 'learning_rate': 3.026759167492567e-05, 'epoch': 23.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4ca01f898a4a098c9986c4d380d22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6313891410827637, 'eval_runtime': 0.4603, 'eval_samples_per_second': 653.882, 'eval_steps_per_second': 82.55, 'epoch': 24.0}\n",
      "{'loss': 0.0749, 'grad_norm': 0.04727589339017868, 'learning_rate': 3.0109018830525276e-05, 'epoch': 24.05}\n",
      "{'loss': 0.0712, 'grad_norm': 0.0237861480563879, 'learning_rate': 2.9950445986124875e-05, 'epoch': 24.24}\n",
      "{'loss': 0.0514, 'grad_norm': 0.03508046641945839, 'learning_rate': 2.979187314172448e-05, 'epoch': 24.43}\n",
      "{'loss': 0.0217, 'grad_norm': 0.02193225733935833, 'learning_rate': 2.9633300297324085e-05, 'epoch': 24.62}\n",
      "{'loss': 0.0587, 'grad_norm': 0.03423648327589035, 'learning_rate': 2.947472745292369e-05, 'epoch': 24.8}\n",
      "{'loss': 0.0605, 'grad_norm': 0.13747842609882355, 'learning_rate': 2.9316154608523296e-05, 'epoch': 24.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4de9ca1a5014f52ac4741b7da49c5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6243276596069336, 'eval_runtime': 0.451, 'eval_samples_per_second': 667.432, 'eval_steps_per_second': 84.261, 'epoch': 25.0}\n",
      "{'loss': 0.0415, 'grad_norm': 0.03185749053955078, 'learning_rate': 2.9157581764122894e-05, 'epoch': 25.18}\n",
      "{'loss': 0.051, 'grad_norm': 0.03303517401218414, 'learning_rate': 2.89990089197225e-05, 'epoch': 25.37}\n",
      "{'loss': 0.0651, 'grad_norm': 0.038750045001506805, 'learning_rate': 2.88404360753221e-05, 'epoch': 25.56}\n",
      "{'loss': 0.0724, 'grad_norm': 0.03225395828485489, 'learning_rate': 2.8681863230921706e-05, 'epoch': 25.75}\n",
      "{'loss': 0.085, 'grad_norm': 4.5789642333984375, 'learning_rate': 2.852329038652131e-05, 'epoch': 25.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b004eadd8cb540778e509e44b802717a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3764007091522217, 'eval_runtime': 0.4293, 'eval_samples_per_second': 701.084, 'eval_steps_per_second': 88.509, 'epoch': 26.0}\n",
      "{'loss': 0.0261, 'grad_norm': 0.025181969627738, 'learning_rate': 2.836471754212091e-05, 'epoch': 26.13}\n",
      "{'loss': 0.0187, 'grad_norm': 0.013905364088714123, 'learning_rate': 2.8206144697720515e-05, 'epoch': 26.32}\n",
      "{'loss': 0.0553, 'grad_norm': 0.013183834962546825, 'learning_rate': 2.804757185332012e-05, 'epoch': 26.51}\n",
      "{'loss': 0.0533, 'grad_norm': 0.03705921024084091, 'learning_rate': 2.7888999008919725e-05, 'epoch': 26.7}\n",
      "{'loss': 0.0512, 'grad_norm': 0.026570657268166542, 'learning_rate': 2.773042616451933e-05, 'epoch': 26.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4dd8be0bb348ca996e7b43c1566fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.804382085800171, 'eval_runtime': 0.4693, 'eval_samples_per_second': 641.328, 'eval_steps_per_second': 80.965, 'epoch': 27.0}\n",
      "{'loss': 0.0214, 'grad_norm': 0.025441577658057213, 'learning_rate': 2.757185332011893e-05, 'epoch': 27.08}\n",
      "{'loss': 0.0349, 'grad_norm': 0.017408262938261032, 'learning_rate': 2.7413280475718534e-05, 'epoch': 27.27}\n",
      "{'loss': 0.0237, 'grad_norm': 0.010363355278968811, 'learning_rate': 2.725470763131814e-05, 'epoch': 27.46}\n",
      "{'loss': 0.0472, 'grad_norm': 0.052304066717624664, 'learning_rate': 2.7096134786917744e-05, 'epoch': 27.64}\n",
      "{'loss': 0.0508, 'grad_norm': 0.014273088425397873, 'learning_rate': 2.6937561942517346e-05, 'epoch': 27.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd8ef13977842f8a725e522298d161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.863097667694092, 'eval_runtime': 0.4531, 'eval_samples_per_second': 664.313, 'eval_steps_per_second': 83.867, 'epoch': 28.0}\n",
      "{'loss': 0.0366, 'grad_norm': 0.08158412575721741, 'learning_rate': 2.6778989098116948e-05, 'epoch': 28.02}\n",
      "{'loss': 0.0345, 'grad_norm': 0.009325769729912281, 'learning_rate': 2.662041625371655e-05, 'epoch': 28.21}\n",
      "{'loss': 0.0302, 'grad_norm': 0.01178362313657999, 'learning_rate': 2.6461843409316155e-05, 'epoch': 28.4}\n",
      "{'loss': 0.0388, 'grad_norm': 0.010158725082874298, 'learning_rate': 2.630327056491576e-05, 'epoch': 28.59}\n",
      "{'loss': 0.0602, 'grad_norm': 0.015401317737996578, 'learning_rate': 2.6144697720515365e-05, 'epoch': 28.78}\n",
      "{'loss': 0.0463, 'grad_norm': 0.009758458472788334, 'learning_rate': 2.5986124876114964e-05, 'epoch': 28.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0202cadfddd8412bb57f8c0624b2f507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.099663019180298, 'eval_runtime': 0.4915, 'eval_samples_per_second': 612.381, 'eval_steps_per_second': 77.311, 'epoch': 29.0}\n",
      "{'loss': 0.0087, 'grad_norm': 0.003390358295291662, 'learning_rate': 2.582755203171457e-05, 'epoch': 29.16}\n",
      "{'loss': 0.0024, 'grad_norm': 0.24956145882606506, 'learning_rate': 2.5668979187314174e-05, 'epoch': 29.35}\n",
      "{'loss': 0.0483, 'grad_norm': 0.005009552463889122, 'learning_rate': 2.551040634291378e-05, 'epoch': 29.54}\n",
      "{'loss': 0.0608, 'grad_norm': 44.73107147216797, 'learning_rate': 2.5351833498513384e-05, 'epoch': 29.73}\n",
      "{'loss': 0.0296, 'grad_norm': 0.010207374580204487, 'learning_rate': 2.5193260654112983e-05, 'epoch': 29.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e59b3648ffb47af95c5708def729690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1902101039886475, 'eval_runtime': 0.4691, 'eval_samples_per_second': 641.632, 'eval_steps_per_second': 81.003, 'epoch': 30.0}\n",
      "{'loss': 0.0582, 'grad_norm': 4.730830192565918, 'learning_rate': 2.5034687809712588e-05, 'epoch': 30.11}\n",
      "{'loss': 0.0086, 'grad_norm': 0.008136983960866928, 'learning_rate': 2.4876114965312193e-05, 'epoch': 30.3}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0044052256271243095, 'learning_rate': 2.4717542120911795e-05, 'epoch': 30.49}\n",
      "{'loss': 0.0094, 'grad_norm': 0.002100704237818718, 'learning_rate': 2.4558969276511397e-05, 'epoch': 30.67}\n",
      "{'loss': 0.0083, 'grad_norm': 0.005336292088031769, 'learning_rate': 2.4400396432111002e-05, 'epoch': 30.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6167dab744824b0b9906814338d67de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.908892869949341, 'eval_runtime': 0.4938, 'eval_samples_per_second': 609.5, 'eval_steps_per_second': 76.947, 'epoch': 31.0}\n",
      "{'loss': 0.0048, 'grad_norm': 0.0025890942197293043, 'learning_rate': 2.4241823587710604e-05, 'epoch': 31.05}\n",
      "{'loss': 0.0016, 'grad_norm': 0.0016396219143643975, 'learning_rate': 2.408325074331021e-05, 'epoch': 31.24}\n",
      "{'loss': 0.0277, 'grad_norm': 0.0023076380603015423, 'learning_rate': 2.3924677898909814e-05, 'epoch': 31.43}\n",
      "{'loss': 0.0221, 'grad_norm': 0.0014418956125155091, 'learning_rate': 2.3766105054509416e-05, 'epoch': 31.62}\n",
      "{'loss': 0.0083, 'grad_norm': 0.0019377118442207575, 'learning_rate': 2.360753221010902e-05, 'epoch': 31.81}\n",
      "{'loss': 0.0617, 'grad_norm': 5.385741233825684, 'learning_rate': 2.3448959365708623e-05, 'epoch': 32.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b744bf2b015541c2b498ab0760fd92bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.417510509490967, 'eval_runtime': 0.4176, 'eval_samples_per_second': 720.701, 'eval_steps_per_second': 90.986, 'epoch': 32.0}\n",
      "{'loss': 0.0125, 'grad_norm': 0.005162034183740616, 'learning_rate': 2.3290386521308228e-05, 'epoch': 32.19}\n",
      "{'loss': 0.0337, 'grad_norm': 0.0011648416984826326, 'learning_rate': 2.3131813676907833e-05, 'epoch': 32.38}\n",
      "{'loss': 0.078, 'grad_norm': 0.014888420701026917, 'learning_rate': 2.2973240832507435e-05, 'epoch': 32.57}\n",
      "{'loss': 0.0123, 'grad_norm': 0.009307770989835262, 'learning_rate': 2.281466798810704e-05, 'epoch': 32.76}\n",
      "{'loss': 0.0309, 'grad_norm': 0.0068987226113677025, 'learning_rate': 2.2656095143706642e-05, 'epoch': 32.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6053113237d34099a19a85045c27969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2844793796539307, 'eval_runtime': 0.4413, 'eval_samples_per_second': 682.072, 'eval_steps_per_second': 86.109, 'epoch': 33.0}\n",
      "{'loss': 0.0306, 'grad_norm': 0.006380435079336166, 'learning_rate': 2.2497522299306244e-05, 'epoch': 33.14}\n",
      "{'loss': 0.0166, 'grad_norm': 0.005006866529583931, 'learning_rate': 2.233894945490585e-05, 'epoch': 33.33}\n",
      "{'loss': 0.0095, 'grad_norm': 0.0034499214962124825, 'learning_rate': 2.218037661050545e-05, 'epoch': 33.51}\n",
      "{'loss': 0.0499, 'grad_norm': 0.005936351139098406, 'learning_rate': 2.2021803766105056e-05, 'epoch': 33.7}\n",
      "{'loss': 0.0124, 'grad_norm': 0.002708852756768465, 'learning_rate': 2.1863230921704658e-05, 'epoch': 33.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dbdd05359c48c59476b94d48c789a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3488895893096924, 'eval_runtime': 0.4638, 'eval_samples_per_second': 649.001, 'eval_steps_per_second': 81.934, 'epoch': 34.0}\n",
      "{'loss': 0.031, 'grad_norm': 0.003875602735206485, 'learning_rate': 2.1704658077304263e-05, 'epoch': 34.08}\n",
      "{'loss': 0.0047, 'grad_norm': 0.003009749809280038, 'learning_rate': 2.1546085232903868e-05, 'epoch': 34.27}\n",
      "{'loss': 0.03, 'grad_norm': 0.004336152691394091, 'learning_rate': 2.138751238850347e-05, 'epoch': 34.46}\n",
      "{'loss': 0.0361, 'grad_norm': 0.04630722850561142, 'learning_rate': 2.1228939544103075e-05, 'epoch': 34.65}\n",
      "{'loss': 0.0187, 'grad_norm': 0.007750825956463814, 'learning_rate': 2.1070366699702677e-05, 'epoch': 34.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40caaaa20584d13ac3e6a0899bc3010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9771132469177246, 'eval_runtime': 0.463, 'eval_samples_per_second': 650.14, 'eval_steps_per_second': 82.077, 'epoch': 35.0}\n",
      "{'loss': 0.0272, 'grad_norm': 0.005683201365172863, 'learning_rate': 2.0911793855302282e-05, 'epoch': 35.03}\n",
      "{'loss': 0.0318, 'grad_norm': 0.005336462985724211, 'learning_rate': 2.0753221010901884e-05, 'epoch': 35.22}\n",
      "{'loss': 0.0202, 'grad_norm': 0.00877355970442295, 'learning_rate': 2.059464816650149e-05, 'epoch': 35.41}\n",
      "{'loss': 0.014, 'grad_norm': 0.004299522377550602, 'learning_rate': 2.043607532210109e-05, 'epoch': 35.6}\n",
      "{'loss': 0.0377, 'grad_norm': 0.0036984721664339304, 'learning_rate': 2.0277502477700693e-05, 'epoch': 35.79}\n",
      "{'loss': 0.0096, 'grad_norm': 0.002779121743515134, 'learning_rate': 2.0118929633300298e-05, 'epoch': 35.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e128cfb0ce4dd2805e91c3125ac846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4838125705718994, 'eval_runtime': 0.4622, 'eval_samples_per_second': 651.206, 'eval_steps_per_second': 82.212, 'epoch': 36.0}\n",
      "{'loss': 0.0668, 'grad_norm': 0.00595412403345108, 'learning_rate': 1.99603567888999e-05, 'epoch': 36.17}\n",
      "{'loss': 0.0118, 'grad_norm': 0.00814381055533886, 'learning_rate': 1.9801783944499505e-05, 'epoch': 36.36}\n",
      "{'loss': 0.0336, 'grad_norm': 0.008707036264240742, 'learning_rate': 1.964321110009911e-05, 'epoch': 36.54}\n",
      "{'loss': 0.0005, 'grad_norm': 0.006613660138100386, 'learning_rate': 1.9484638255698712e-05, 'epoch': 36.73}\n",
      "{'loss': 0.0256, 'grad_norm': 0.006116582080721855, 'learning_rate': 1.9326065411298317e-05, 'epoch': 36.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77030ad7027b48a5bbd32e6a82314207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.164886236190796, 'eval_runtime': 0.4523, 'eval_samples_per_second': 665.474, 'eval_steps_per_second': 84.013, 'epoch': 37.0}\n",
      "{'loss': 0.0196, 'grad_norm': 0.00521282572299242, 'learning_rate': 1.916749256689792e-05, 'epoch': 37.11}\n",
      "{'loss': 0.0042, 'grad_norm': 0.004273474216461182, 'learning_rate': 1.9008919722497524e-05, 'epoch': 37.3}\n",
      "{'loss': 0.0336, 'grad_norm': 0.003832561895251274, 'learning_rate': 1.885034687809713e-05, 'epoch': 37.49}\n",
      "{'loss': 0.0174, 'grad_norm': 0.0036097709089517593, 'learning_rate': 1.869177403369673e-05, 'epoch': 37.68}\n",
      "{'loss': 0.0321, 'grad_norm': 0.0033442217390984297, 'learning_rate': 1.8533201189296333e-05, 'epoch': 37.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a772cf371a0425b9a12ed4586fb7704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.408343553543091, 'eval_runtime': 0.4753, 'eval_samples_per_second': 633.34, 'eval_steps_per_second': 79.957, 'epoch': 38.0}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0028006352949887514, 'learning_rate': 1.8374628344895934e-05, 'epoch': 38.06}\n",
      "{'loss': 0.0147, 'grad_norm': 0.002328965812921524, 'learning_rate': 1.821605550049554e-05, 'epoch': 38.25}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0019132787128910422, 'learning_rate': 1.8057482656095145e-05, 'epoch': 38.44}\n",
      "{'loss': 0.0045, 'grad_norm': 0.0019087810069322586, 'learning_rate': 1.7898909811694747e-05, 'epoch': 38.63}\n",
      "{'loss': 0.0099, 'grad_norm': 0.0015835656085982919, 'learning_rate': 1.7740336967294352e-05, 'epoch': 38.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fd5399ebae4b8980cefa3b6c9022ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3503384590148926, 'eval_runtime': 0.4319, 'eval_samples_per_second': 696.892, 'eval_steps_per_second': 87.98, 'epoch': 39.0}\n",
      "{'loss': 0.0186, 'grad_norm': 0.0028351531364023685, 'learning_rate': 1.7581764122893954e-05, 'epoch': 39.01}\n",
      "{'loss': 0.0052, 'grad_norm': 0.005130094010382891, 'learning_rate': 1.742319127849356e-05, 'epoch': 39.2}\n",
      "{'loss': 0.0146, 'grad_norm': 0.0026571042835712433, 'learning_rate': 1.7264618434093164e-05, 'epoch': 39.38}\n",
      "{'loss': 0.0178, 'grad_norm': 0.002080877311527729, 'learning_rate': 1.7106045589692766e-05, 'epoch': 39.57}\n",
      "{'loss': 0.0065, 'grad_norm': 0.00204435084015131, 'learning_rate': 1.694747274529237e-05, 'epoch': 39.76}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0016484011430293322, 'learning_rate': 1.6788899900891973e-05, 'epoch': 39.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db22c216a28440b19dcd858f188927b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4793057441711426, 'eval_runtime': 0.4718, 'eval_samples_per_second': 638.006, 'eval_steps_per_second': 80.546, 'epoch': 40.0}\n",
      "{'loss': 0.0054, 'grad_norm': 0.0017145663732662797, 'learning_rate': 1.6630327056491578e-05, 'epoch': 40.14}\n",
      "{'loss': 0.0145, 'grad_norm': 0.0012537742732092738, 'learning_rate': 1.647175421209118e-05, 'epoch': 40.33}\n",
      "{'loss': 0.0041, 'grad_norm': 0.0009299708181060851, 'learning_rate': 1.631318136769078e-05, 'epoch': 40.52}\n",
      "{'loss': 0.084, 'grad_norm': 0.00314721348695457, 'learning_rate': 1.6154608523290387e-05, 'epoch': 40.71}\n",
      "{'loss': 0.0212, 'grad_norm': 0.01250982005149126, 'learning_rate': 1.599603567888999e-05, 'epoch': 40.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28127a16eb9540a3b6191d34f4802aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.5049946308135986, 'eval_runtime': 0.4245, 'eval_samples_per_second': 709.069, 'eval_steps_per_second': 89.517, 'epoch': 41.0}\n",
      "{'loss': 0.0005, 'grad_norm': 0.002394643146544695, 'learning_rate': 1.5837462834489594e-05, 'epoch': 41.09}\n",
      "{'loss': 0.0047, 'grad_norm': 0.0018144118366762996, 'learning_rate': 1.56788899900892e-05, 'epoch': 41.28}\n",
      "{'loss': 0.0432, 'grad_norm': 0.004965888801962137, 'learning_rate': 1.55203171456888e-05, 'epoch': 41.47}\n",
      "{'loss': 0.0335, 'grad_norm': 0.004450729116797447, 'learning_rate': 1.5361744301288406e-05, 'epoch': 41.66}\n",
      "{'loss': 0.0316, 'grad_norm': 0.006762966047972441, 'learning_rate': 1.5203171456888008e-05, 'epoch': 41.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bebf0b805a74ed8b9573377ae2d5a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2602202892303467, 'eval_runtime': 0.4305, 'eval_samples_per_second': 699.254, 'eval_steps_per_second': 88.278, 'epoch': 42.0}\n",
      "{'loss': 0.0133, 'grad_norm': 0.7395436763763428, 'learning_rate': 1.5044598612487613e-05, 'epoch': 42.04}\n",
      "{'loss': 0.039, 'grad_norm': 0.005160906817764044, 'learning_rate': 1.4886025768087216e-05, 'epoch': 42.22}\n",
      "{'loss': 0.0116, 'grad_norm': 0.007687818259000778, 'learning_rate': 1.4727452923686818e-05, 'epoch': 42.41}\n",
      "{'loss': 0.0035, 'grad_norm': 0.002736529102548957, 'learning_rate': 1.4568880079286423e-05, 'epoch': 42.6}\n",
      "{'loss': 0.0225, 'grad_norm': 51.8704719543457, 'learning_rate': 1.4410307234886025e-05, 'epoch': 42.79}\n",
      "{'loss': 0.0266, 'grad_norm': 0.002920215018093586, 'learning_rate': 1.425173439048563e-05, 'epoch': 42.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f5a8711c0f437085db35086d9a1b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.248683214187622, 'eval_runtime': 0.4504, 'eval_samples_per_second': 668.236, 'eval_steps_per_second': 84.362, 'epoch': 43.0}\n",
      "{'loss': 0.0217, 'grad_norm': 0.0023979833349585533, 'learning_rate': 1.4093161546085235e-05, 'epoch': 43.17}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0020470679737627506, 'learning_rate': 1.3934588701684837e-05, 'epoch': 43.36}\n",
      "{'loss': 0.0052, 'grad_norm': 0.0017744377255439758, 'learning_rate': 1.377601585728444e-05, 'epoch': 43.55}\n",
      "{'loss': 0.0212, 'grad_norm': 0.001869797590188682, 'learning_rate': 1.3617443012884042e-05, 'epoch': 43.74}\n",
      "{'loss': 0.0202, 'grad_norm': 0.05034260079264641, 'learning_rate': 1.3458870168483648e-05, 'epoch': 43.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50601bd66c5d4a9394d7aafda7cc94da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.5185160636901855, 'eval_runtime': 0.4464, 'eval_samples_per_second': 674.291, 'eval_steps_per_second': 85.126, 'epoch': 44.0}\n",
      "{'loss': 0.0068, 'grad_norm': 0.0016651086043566465, 'learning_rate': 1.3300297324083253e-05, 'epoch': 44.12}\n",
      "{'loss': 0.0115, 'grad_norm': 0.0012088923249393702, 'learning_rate': 1.3141724479682855e-05, 'epoch': 44.31}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0014367492403835058, 'learning_rate': 1.298315163528246e-05, 'epoch': 44.5}\n",
      "{'loss': 0.0011, 'grad_norm': 0.0012642258079722524, 'learning_rate': 1.2824578790882061e-05, 'epoch': 44.69}\n",
      "{'loss': 0.0, 'grad_norm': 0.0010698373662307858, 'learning_rate': 1.2666005946481665e-05, 'epoch': 44.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8ad1ec3df44150a53f76e49b495dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8861021995544434, 'eval_runtime': 0.4489, 'eval_samples_per_second': 670.456, 'eval_steps_per_second': 84.642, 'epoch': 45.0}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0010956083424389362, 'learning_rate': 1.250743310208127e-05, 'epoch': 45.07}\n",
      "{'loss': 0.0006, 'grad_norm': 0.01666136272251606, 'learning_rate': 1.2348860257680872e-05, 'epoch': 45.25}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0009146938100457191, 'learning_rate': 1.2190287413280477e-05, 'epoch': 45.44}\n",
      "{'loss': 0.0269, 'grad_norm': 0.0011637321440503001, 'learning_rate': 1.203171456888008e-05, 'epoch': 45.63}\n",
      "{'loss': 0.0032, 'grad_norm': 0.0011921339901164174, 'learning_rate': 1.1873141724479684e-05, 'epoch': 45.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bf04a9db4d42b782fee769b47b7572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.823268175125122, 'eval_runtime': 0.4363, 'eval_samples_per_second': 689.83, 'eval_steps_per_second': 87.088, 'epoch': 46.0}\n",
      "{'loss': 0.0047, 'grad_norm': 0.0007324812468141317, 'learning_rate': 1.1714568880079286e-05, 'epoch': 46.01}\n",
      "{'loss': 0.0088, 'grad_norm': 0.0008322292705997825, 'learning_rate': 1.155599603567889e-05, 'epoch': 46.2}\n",
      "{'loss': 0.0012, 'grad_norm': 0.0007522257510572672, 'learning_rate': 1.1397423191278495e-05, 'epoch': 46.39}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005132006481289864, 'learning_rate': 1.1238850346878098e-05, 'epoch': 46.58}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006474812398664653, 'learning_rate': 1.1080277502477702e-05, 'epoch': 46.77}\n",
      "{'loss': 0.0236, 'grad_norm': 0.0007921892683953047, 'learning_rate': 1.0921704658077305e-05, 'epoch': 46.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a2d13becd74763b894c02f5cd22b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8740592002868652, 'eval_runtime': 0.4416, 'eval_samples_per_second': 681.635, 'eval_steps_per_second': 86.054, 'epoch': 47.0}\n",
      "{'loss': 0.0052, 'grad_norm': 0.0006654560565948486, 'learning_rate': 1.0763131813676909e-05, 'epoch': 47.15}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006534887361340225, 'learning_rate': 1.0604558969276512e-05, 'epoch': 47.34}\n",
      "{'loss': 0.005, 'grad_norm': 0.0005682869232259691, 'learning_rate': 1.0445986124876115e-05, 'epoch': 47.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.00045344277168624103, 'learning_rate': 1.0287413280475719e-05, 'epoch': 47.72}\n",
      "{'loss': 0.0037, 'grad_norm': 0.00048727920511737466, 'learning_rate': 1.0128840436075322e-05, 'epoch': 47.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc24fb11f0304b17806ec0e63e8ab10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.245433330535889, 'eval_runtime': 0.4666, 'eval_samples_per_second': 645.1, 'eval_steps_per_second': 81.441, 'epoch': 48.0}\n",
      "{'loss': 0.0005, 'grad_norm': 0.00043002443271689117, 'learning_rate': 9.970267591674926e-06, 'epoch': 48.09}\n",
      "{'loss': 0.0241, 'grad_norm': 0.0005114767118357122, 'learning_rate': 9.81169474727453e-06, 'epoch': 48.28}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006221569492481649, 'learning_rate': 9.653121902874133e-06, 'epoch': 48.47}\n",
      "{'loss': 0.0104, 'grad_norm': 0.0006499968003481627, 'learning_rate': 9.494549058473736e-06, 'epoch': 48.66}\n",
      "{'loss': 0.0142, 'grad_norm': 0.00039556564297527075, 'learning_rate': 9.33597621407334e-06, 'epoch': 48.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c2ca3d5ffc4a109527e4d86954b2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.033597946166992, 'eval_runtime': 0.4426, 'eval_samples_per_second': 680.018, 'eval_steps_per_second': 85.849, 'epoch': 49.0}\n",
      "{'loss': 0.0131, 'grad_norm': 0.0003589594562072307, 'learning_rate': 9.177403369672943e-06, 'epoch': 49.04}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00041473106830380857, 'learning_rate': 9.018830525272549e-06, 'epoch': 49.23}\n",
      "{'loss': 0.0071, 'grad_norm': 0.00034503170172683895, 'learning_rate': 8.860257680872152e-06, 'epoch': 49.42}\n",
      "{'loss': 0.003, 'grad_norm': 0.00034914936986751854, 'learning_rate': 8.701684836471754e-06, 'epoch': 49.61}\n",
      "{'loss': 0.0007, 'grad_norm': 0.0005516994278877974, 'learning_rate': 8.543111992071357e-06, 'epoch': 49.8}\n",
      "{'loss': 0.0034, 'grad_norm': 0.0003427433257456869, 'learning_rate': 8.38453914767096e-06, 'epoch': 49.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ce40da4f164aca9b0b3b04a3abefe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.274878978729248, 'eval_runtime': 0.4382, 'eval_samples_per_second': 686.839, 'eval_steps_per_second': 86.711, 'epoch': 50.0}\n",
      "{'loss': 0.0347, 'grad_norm': 0.0003477807331364602, 'learning_rate': 8.225966303270566e-06, 'epoch': 50.18}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002922042622230947, 'learning_rate': 8.06739345887017e-06, 'epoch': 50.37}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0003724189009517431, 'learning_rate': 7.908820614469773e-06, 'epoch': 50.56}\n",
      "{'loss': 0.0041, 'grad_norm': 0.0004327110364101827, 'learning_rate': 7.750247770069376e-06, 'epoch': 50.75}\n",
      "{'loss': 0.0004, 'grad_norm': 0.00035348007804714143, 'learning_rate': 7.591674925668979e-06, 'epoch': 50.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad1c45d95f14d6184b9eeac8a0a7416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.128835678100586, 'eval_runtime': 0.4632, 'eval_samples_per_second': 649.798, 'eval_steps_per_second': 82.034, 'epoch': 51.0}\n",
      "{'loss': 0.0037, 'grad_norm': 0.000349819049006328, 'learning_rate': 7.433102081268583e-06, 'epoch': 51.12}\n",
      "{'loss': 0.0084, 'grad_norm': 0.00027237081667408347, 'learning_rate': 7.274529236868187e-06, 'epoch': 51.31}\n",
      "{'loss': 0.0075, 'grad_norm': 0.00035052470047958195, 'learning_rate': 7.11595639246779e-06, 'epoch': 51.5}\n",
      "{'loss': 0.0035, 'grad_norm': 0.0002791848673950881, 'learning_rate': 6.957383548067394e-06, 'epoch': 51.69}\n",
      "{'loss': 0.0046, 'grad_norm': 0.00024399280664511025, 'learning_rate': 6.7988107036669965e-06, 'epoch': 51.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946f0f286707490287a095a732603ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.1756415367126465, 'eval_runtime': 0.4781, 'eval_samples_per_second': 629.558, 'eval_steps_per_second': 79.479, 'epoch': 52.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.00031010917155072093, 'learning_rate': 6.640237859266602e-06, 'epoch': 52.07}\n",
      "{'loss': 0.0036, 'grad_norm': 0.0002919088292401284, 'learning_rate': 6.481665014866205e-06, 'epoch': 52.26}\n",
      "{'loss': 0.0081, 'grad_norm': 0.00024121308524627239, 'learning_rate': 6.323092170465808e-06, 'epoch': 52.45}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002928042958956212, 'learning_rate': 6.164519326065411e-06, 'epoch': 52.64}\n",
      "{'loss': 0.0005, 'grad_norm': 0.00028232435579411685, 'learning_rate': 6.005946481665016e-06, 'epoch': 52.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eec12176654d57a87a9e125bef1a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.226504802703857, 'eval_runtime': 0.4582, 'eval_samples_per_second': 656.91, 'eval_steps_per_second': 82.932, 'epoch': 53.0}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0002828784636221826, 'learning_rate': 5.847373637264618e-06, 'epoch': 53.02}\n",
      "{'loss': 0.0064, 'grad_norm': 0.00023315922589972615, 'learning_rate': 5.688800792864223e-06, 'epoch': 53.21}\n",
      "{'loss': 0.0006, 'grad_norm': 0.00024631209089420736, 'learning_rate': 5.530227948463826e-06, 'epoch': 53.4}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002522469440009445, 'learning_rate': 5.371655104063429e-06, 'epoch': 53.59}\n",
      "{'loss': 0.0, 'grad_norm': 0.00022704883303958923, 'learning_rate': 5.213082259663033e-06, 'epoch': 53.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002361450024181977, 'learning_rate': 5.0545094152626366e-06, 'epoch': 53.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eda8e23ed284a86b5777702bf69d718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.328869819641113, 'eval_runtime': 0.4605, 'eval_samples_per_second': 653.67, 'eval_steps_per_second': 82.523, 'epoch': 54.0}\n",
      "{'loss': 0.0034, 'grad_norm': 0.0004598270170390606, 'learning_rate': 4.89593657086224e-06, 'epoch': 54.15}\n",
      "{'loss': 0.0032, 'grad_norm': 0.00019949862326029688, 'learning_rate': 4.7373637264618435e-06, 'epoch': 54.34}\n",
      "{'loss': 0.001, 'grad_norm': 0.0002802900562528521, 'learning_rate': 4.578790882061447e-06, 'epoch': 54.53}\n",
      "{'loss': 0.0035, 'grad_norm': 0.00017801269132178277, 'learning_rate': 4.420218037661051e-06, 'epoch': 54.72}\n",
      "{'loss': 0.0037, 'grad_norm': 0.00019937168690375984, 'learning_rate': 4.261645193260654e-06, 'epoch': 54.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e735239d484d479482fe4d2699bbac1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.355216979980469, 'eval_runtime': 0.4451, 'eval_samples_per_second': 676.277, 'eval_steps_per_second': 85.377, 'epoch': 55.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002143089077435434, 'learning_rate': 4.103072348860258e-06, 'epoch': 55.1}\n",
      "{'loss': 0.0044, 'grad_norm': 0.0002033208147622645, 'learning_rate': 3.944499504459862e-06, 'epoch': 55.29}\n",
      "{'loss': 0.0036, 'grad_norm': 0.00021103878680150956, 'learning_rate': 3.785926660059465e-06, 'epoch': 55.48}\n",
      "{'loss': 0.0, 'grad_norm': 0.00018220333731733263, 'learning_rate': 3.6273538156590688e-06, 'epoch': 55.67}\n",
      "{'loss': 0.0026, 'grad_norm': 0.00021847669268026948, 'learning_rate': 3.468780971258672e-06, 'epoch': 55.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239ea22396704984b6bda47d9d815dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.432544231414795, 'eval_runtime': 0.4334, 'eval_samples_per_second': 694.481, 'eval_steps_per_second': 87.675, 'epoch': 56.0}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0001759378210408613, 'learning_rate': 3.3102081268582753e-06, 'epoch': 56.05}\n",
      "{'loss': 0.006, 'grad_norm': 0.00020708593365270644, 'learning_rate': 3.1516352824578792e-06, 'epoch': 56.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.00020116228552069515, 'learning_rate': 2.993062438057483e-06, 'epoch': 56.43}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0004432880668900907, 'learning_rate': 2.834489593657086e-06, 'epoch': 56.62}\n",
      "{'loss': 0.0004, 'grad_norm': 0.00020082721312064677, 'learning_rate': 2.6759167492566897e-06, 'epoch': 56.8}\n",
      "{'loss': 0.0024, 'grad_norm': 0.00022360584989655763, 'learning_rate': 2.5173439048562936e-06, 'epoch': 56.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484d9d027c7f48c699b192534743d7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.4718918800354, 'eval_runtime': 0.4455, 'eval_samples_per_second': 675.666, 'eval_steps_per_second': 85.3, 'epoch': 57.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00019596666970755905, 'learning_rate': 2.358771060455897e-06, 'epoch': 57.18}\n",
      "{'loss': 0.0015, 'grad_norm': 0.00019668419554363936, 'learning_rate': 2.2001982160555006e-06, 'epoch': 57.37}\n",
      "{'loss': 0.0034, 'grad_norm': 0.000189046812010929, 'learning_rate': 2.041625371655104e-06, 'epoch': 57.56}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001948989083757624, 'learning_rate': 1.8830525272547078e-06, 'epoch': 57.75}\n",
      "{'loss': 0.0028, 'grad_norm': 0.0001889422710519284, 'learning_rate': 1.7244796828543112e-06, 'epoch': 57.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfedb43a78c4dfe8ee957c746a2ace6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.568084239959717, 'eval_runtime': 0.4525, 'eval_samples_per_second': 665.201, 'eval_steps_per_second': 83.979, 'epoch': 58.0}\n",
      "{'loss': 0.0037, 'grad_norm': 0.00019471711129881442, 'learning_rate': 1.565906838453915e-06, 'epoch': 58.13}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019216921646147966, 'learning_rate': 1.4073339940535184e-06, 'epoch': 58.32}\n",
      "{'loss': 0.0037, 'grad_norm': 0.00025626926799304783, 'learning_rate': 1.2487611496531221e-06, 'epoch': 58.51}\n",
      "{'loss': 0.0034, 'grad_norm': 0.00016013451386243105, 'learning_rate': 1.0901883052527254e-06, 'epoch': 58.7}\n",
      "{'loss': 0.0036, 'grad_norm': 0.00017847222625277936, 'learning_rate': 9.316154608523291e-07, 'epoch': 58.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7092b76ec06d4669867b257c6673dc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.578721046447754, 'eval_runtime': 0.4484, 'eval_samples_per_second': 671.245, 'eval_steps_per_second': 84.742, 'epoch': 59.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019013193377759308, 'learning_rate': 7.730426164519327e-07, 'epoch': 59.08}\n",
      "{'loss': 0.0007, 'grad_norm': 0.00018648729019332677, 'learning_rate': 6.144697720515362e-07, 'epoch': 59.27}\n",
      "{'loss': 0.0, 'grad_norm': 0.00014438832295127213, 'learning_rate': 4.5589692765113977e-07, 'epoch': 59.46}\n",
      "{'loss': 0.0007, 'grad_norm': 0.0001576225331518799, 'learning_rate': 2.973240832507433e-07, 'epoch': 59.64}\n",
      "{'loss': 0.0061, 'grad_norm': 0.00017922157712746412, 'learning_rate': 1.387512388503469e-07, 'epoch': 59.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7202f1e95c5b473d9b77356ba9236249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.582746505737305, 'eval_runtime': 0.4314, 'eval_samples_per_second': 697.799, 'eval_steps_per_second': 88.094, 'epoch': 60.0}\n",
      "{'train_runtime': 1389.1812, 'train_samples_per_second': 116.745, 'train_steps_per_second': 14.599, 'train_loss': 0.11268299733740154, 'epoch': 60.0}\n",
      "Total training time: 0:23:9\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "trainer = Trainer(model=model_bert, \n",
    "                  args=training_args, \n",
    "                  train_dataset=tokenized_data['train'], \n",
    "                  eval_dataset=tokenized_data['validation'], \n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "\n",
    "total_training_time = end_time - start_time\n",
    "\n",
    "# Convert total_training_time to hours, minutes, and seconds\n",
    "hours = int(total_training_time // 3600)\n",
    "minutes = int((total_training_time % 3600) // 60)\n",
    "seconds = int(total_training_time % 60)\n",
    "\n",
    "print(f\"Total training time: {hours}:{minutes}:{seconds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e68a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b12eb34a",
   "metadata": {},
   "source": [
    "# PPO\n",
    "Defining a configuration object for the Proximal Policy Optimization (PPO) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e90179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import set_seed\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "from random import choices\n",
    "from trl import PPOTrainer\n",
    "from trl import PPOConfig\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import transformers \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert_score\n",
    "import ipywidgets\n",
    "import datasets\n",
    "import evaluate\n",
    "import logging\n",
    "import jupyter\n",
    "import random\n",
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import trl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c270f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None\n",
    "np.random.seed(123)\n",
    "tqdm.pandas()\n",
    "set_seed = args.set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17909303",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4080cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahil\\.conda\\envs\\genai\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:150: UserWarning: Note that using `forward_batch_size` is deprecated, use `mini_batch_size` instead. By setting it you overwrite `mini_batch_size` which affects both the batch size during forward passes and also the mini batch size for PPO optimization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = PPOConfig(model_name=args.output_dir + '/train/finetuned', \n",
    "                   batch_size=args.batch_size,\n",
    "                   learning_rate=args.learning_rate, #1.41e-6,\n",
    "                   forward_batch_size=args.batch_size, # This parameter is useful when using large models that don't fit into memory.\n",
    "                   remove_unused_columns=False, # All columns in the input data will be used during training.\n",
    "                   log_with='wandb'# For logging training metrics\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d492b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_model = AutoModelForCausalLMWithValueHead.from_pretrained(args.output_dir)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a26a5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Yeshiva\\\\Spring24\\\\AI\\\\katzbot\\\\dataset_katzbot/Test_QA_Pairs.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45652d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853e795da28f47a28f46ba5bc279b8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 2081\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', \n",
    "                       data_files=args.test_data,  \n",
    "                       delimiter=',', \n",
    "                       split='train[:100%]',\n",
    "                       download_mode='force_redownload')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1bcea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12454a6e9922466c922f1e2aada3847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'query', 'ground_truth', 'questions'],\n",
       "    num_rows: 2081\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(samples: list):\n",
    "    questions = samples['question']\n",
    "    ground_truth = samples['answer']\n",
    "    \n",
    "    input_ids = []\n",
    "    query = []\n",
    "    \n",
    "    for question in questions:\n",
    "        prompted_input = f'question: {question}\\nanswer:'\n",
    "        query.append(prompted_input)\n",
    "        tokenized_input = tokenizer(prompted_input, \n",
    "                                    truncation=True)\n",
    "        input_ids.append(torch.tensor(tokenized_input['input_ids'], dtype=torch.long))\n",
    "        \n",
    "    return {'input_ids': input_ids, 'query': query, 'ground_truth': ground_truth, 'questions': questions}\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.map(tokenize, \n",
    "                      batched=True, \n",
    "                      #num_proc=num_proc, \n",
    "                      load_from_cache_file=False, \n",
    "                      remove_columns=['question', 'answer'])\n",
    "dataset.set_format('pt', \n",
    "                   columns=['input_ids', 'query', 'ground_truth'],\n",
    "                   output_all_columns=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "389f1e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:33284civ) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b974f28485c41a68b642468bb96115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>4.58275</td></tr><tr><td>eval/runtime</td><td>0.4314</td></tr><tr><td>eval/samples_per_second</td><td>697.799</td></tr><tr><td>eval/steps_per_second</td><td>88.094</td></tr><tr><td>train/epoch</td><td>60.0</td></tr><tr><td>train/global_step</td><td>20280</td></tr><tr><td>train/grad_norm</td><td>0.00018</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0061</td></tr><tr><td>train/total_flos</td><td>1.247294453763918e+16</td></tr><tr><td>train/train_loss</td><td>0.11268</td></tr><tr><td>train/train_runtime</td><td>1389.1812</td></tr><tr><td>train/train_samples_per_second</td><td>116.745</td></tr><tr><td>train/train_steps_per_second</td><td>14.599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scruffy-looking-astromech-9</strong> at: <a href='https://wandb.ai/sahilthegnius/huggingface/runs/33284civ' target=\"_blank\">https://wandb.ai/sahilthegnius/huggingface/runs/33284civ</a><br/> View project at: <a href='https://wandb.ai/sahilthegnius/huggingface' target=\"_blank\">https://wandb.ai/sahilthegnius/huggingface</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240504_154821-33284civ\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:33284civ). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5df26a1f04e47f9a6f7f36ec51e5204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Yeshiva\\Spring24\\AI\\katzbot_6\\wandb\\run-20240504_161131-32y7mqxt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sahilthegnius/trl/runs/32y7mqxt' target=\"_blank\">dark-podracer-6</a></strong> to <a href='https://wandb.ai/sahilthegnius/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sahilthegnius/trl' target=\"_blank\">https://wandb.ai/sahilthegnius/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sahilthegnius/trl/runs/32y7mqxt' target=\"_blank\">https://wandb.ai/sahilthegnius/trl/runs/32y7mqxt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def collator(dataset):\n",
    "    result = {}\n",
    "    for key in dataset[0]:\n",
    "        values = []\n",
    "        for d in dataset:\n",
    "            values.append(d[key])\n",
    "        result[key] = values\n",
    "    return result\n",
    "\n",
    "# creates an instance of the PPOTrainer class\n",
    "ppo_trainer = PPOTrainer(config, active_model, ref_model, tokenizer, dataset=dataset, data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64fbb2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "bert_pipe = pipeline('text-generation', \n",
    "                     model=args.output_dir,\n",
    "                    max_length = args.MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01b9cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Weberf, Syms, and the Sy Syms School of Business.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "prompt = \"Are there clubs and associations that students can join?\"\n",
    "output = bert_pipe(prompt, max_length=512, num_return_sequences=1)\n",
    "output = output[0]['generated_text']\n",
    "response_text = output.split('[RESPONSE]')[1]\n",
    "formatted_text = \"```\\n\" + response_text + \"\\n```\"\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e54bdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "The student community on campus is vibrant and has been diverse for ages.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# prompt = \"Are there clubs and associations that students can join?\"\n",
    "prompt =\"How active is the student community on campus?\"\n",
    "output = bert_pipe(prompt, max_length=512, num_return_sequences=1)\n",
    "output = output[0]['generated_text']\n",
    "response_text = output.split('[RESPONSE]')[1]\n",
    "formatted_text = \"```\\n\" + response_text + \"\\n```\"\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3043b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student community on campus is vibrant and has been diverse for ages.\n"
     ]
    }
   ],
   "source": [
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "382693e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the student community on campus is vibrant and diverse, with over 70,000 people.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def generate_response(prompt: str, bert_pipe):\n",
    "    # Generate response using the BERT-based pipeline\n",
    "    output = bert_pipe(prompt, max_length=512, num_return_sequences=1, pad_token_id=50256)\n",
    "    output = output[0]['generated_text']\n",
    "    response_text = output.split('[RESPONSE]')[1].strip() if output else \"No response found\"\n",
    "    return response_text\n",
    "\n",
    "# Example usage:\n",
    "prompt = \"How active is the student community on campus?\"\n",
    "response = generate_response(prompt, bert_pipe)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12dc2c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2081, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the student/faculty ratio at this university?</td>\n",
       "      <td>The student/faculty ratio at Yeshiva University is 7:1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How often do students get to interact with professors outside of class?</td>\n",
       "      <td>Students at Yeshiva University have ample opportunities to interact with professors outside of class through office hours, research projects, and mentoring programs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How active is the student community on campus?</td>\n",
       "      <td>The student community at Yeshiva University is highly active, with various clubs, organizations, and events that foster a strong sense of community on campus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you tell me more about the extracurricular activities offered at this university?</td>\n",
       "      <td>Yeshiva University offers a wide range of extracurricular activities, including cultural clubs, academic societies, volunteer opportunities, and sports teams.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What percentage of students get financial aid?</td>\n",
       "      <td>Approximately 85% of students at Yeshiva University receive some form of financial aid.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                question  \\\n",
       "0                                  What is the student/faculty ratio at this university?   \n",
       "1                How often do students get to interact with professors outside of class?   \n",
       "2                                         How active is the student community on campus?   \n",
       "3  Can you tell me more about the extracurricular activities offered at this university?   \n",
       "4                                         What percentage of students get financial aid?   \n",
       "\n",
       "                                                                                                                                                                  answer  \n",
       "0                                                                                                                The student/faculty ratio at Yeshiva University is 7:1.  \n",
       "1  Students at Yeshiva University have ample opportunities to interact with professors outside of class through office hours, research projects, and mentoring programs.  \n",
       "2         The student community at Yeshiva University is highly active, with various clubs, organizations, and events that foster a strong sense of community on campus.  \n",
       "3         Yeshiva University offers a wide range of extracurricular activities, including cultural clubs, academic societies, volunteer opportunities, and sports teams.  \n",
       "4                                                                                Approximately 85% of students at Yeshiva University receive some form of financial aid.  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_rlhf = pd.read_csv(args.test_data)\n",
    "# df = df.iloc[101:]\n",
    "print(test_df_rlhf.shape)\n",
    "test_df_rlhf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67bbe9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me about yourself?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_rlhf['question'][1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cce2a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Katzbot, created by students from the Artificial Intelligence program at Katz School at Yeshiva under Prof. Youshan Zhangs supervision. My primary goal is to provide students with rapid and accurate responses to their inquiries about our school.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def generate_response(prompt: str, bert_pipe):\n",
    "    # Generate response using the BERT-based pipeline\n",
    "    output = bert_pipe(prompt, max_length=512, num_return_sequences=1, pad_token_id=50256)\n",
    "    output = output[0]['generated_text']\n",
    "    response_text = output.split('[RESPONSE]')[1].strip() if output else \"No response found\"\n",
    "    return response_text\n",
    "\n",
    "# Example usage:\n",
    "prompt = test_df_rlhf['question'][1002]\n",
    "response = generate_response(prompt, bert_pipe)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f5da789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2081/2081 [45:20<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to models_pretrained_4\\predicted_answer_rlhf.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt: str, bert_pipe):\n",
    "    output = bert_pipe(prompt, max_length=512, num_return_sequences=1, pad_token_id=50256)\n",
    "    \n",
    "    # Check if output is empty\n",
    "    if output and len(output) > 0:\n",
    "        output_text = output[0].get('generated_text', '')\n",
    "        # Check if the delimiter is present in output_text\n",
    "        if '[RESPONSE]' in output_text:\n",
    "            response_text = output_text.split('[RESPONSE]')[1].strip()\n",
    "        else:\n",
    "            response_text = \"No response found\"\n",
    "    else:\n",
    "        response_text = \"No response found\"\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "text_file_rlhf = os.path.join(args.output_dir, args.save_text_file_rlhf)\n",
    "answers_rlhf = []\n",
    "\n",
    "with open(text_file_rlhf, 'w') as f:\n",
    "    for i, row in tqdm(test_df_rlhf.iterrows(), total=len(test_df_rlhf)):\n",
    "        question, answer = row\n",
    "        answer_rlhf = generate_response(question, bert_pipe)\n",
    "        answers_rlhf.append(answer_rlhf)\n",
    "        f.write(f\"Question {i+1}/{len(test_df_rlhf)} => {question}\\n\")\n",
    "        f.write(f\"Answer => {answer}\\n\")\n",
    "        f.write(f\"Predicted Answer => {answer_rlhf}\\n\")\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "# Optionally, you can print a message indicating that the output has been saved\n",
    "print(f\"Output saved to {text_file_rlhf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4dbb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72b4a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the student/faculty ratio at this university?</td>\n",
       "      <td>The student/faculty ratio at Yeshiva University is 7:1.</td>\n",
       "      <td>The student was awarded a Master of Science degree by the University of Kansas SpeechLanguageHearing Association.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How often do students get to interact with professors outside of class?</td>\n",
       "      <td>Students at Yeshiva University have ample opportunities to interact with professors outside of class through office hours, research projects, and mentoring programs.</td>\n",
       "      <td>Students get to interact with professors outside of class.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How active is the student community on campus?</td>\n",
       "      <td>The student community at Yeshiva University is highly active, with various clubs, organizations, and events that foster a strong sense of community on campus.</td>\n",
       "      <td>Yes, the student community on campus is vibrant, with over 70,000 Yeshiva University alumni and over 70,000 alumni.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you tell me more about the extracurricular activities offered at this university?</td>\n",
       "      <td>Yeshiva University offers a wide range of extracurricular activities, including cultural clubs, academic societies, volunteer opportunities, and sports teams.</td>\n",
       "      <td>You can tell me more about the opportunities offered at this university by contacting the Student Council or the specific staff members listed above for their respective roles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What percentage of students get financial aid?</td>\n",
       "      <td>Approximately 85% of students at Yeshiva University receive some form of financial aid.</td>\n",
       "      <td>Over 80 of students receive financial assistance.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                question  \\\n",
       "0                                  What is the student/faculty ratio at this university?   \n",
       "1                How often do students get to interact with professors outside of class?   \n",
       "2                                         How active is the student community on campus?   \n",
       "3  Can you tell me more about the extracurricular activities offered at this university?   \n",
       "4                                         What percentage of students get financial aid?   \n",
       "\n",
       "                                                                                                                                                                  answer  \\\n",
       "0                                                                                                                The student/faculty ratio at Yeshiva University is 7:1.   \n",
       "1  Students at Yeshiva University have ample opportunities to interact with professors outside of class through office hours, research projects, and mentoring programs.   \n",
       "2         The student community at Yeshiva University is highly active, with various clubs, organizations, and events that foster a strong sense of community on campus.   \n",
       "3         Yeshiva University offers a wide range of extracurricular activities, including cultural clubs, academic societies, volunteer opportunities, and sports teams.   \n",
       "4                                                                                Approximately 85% of students at Yeshiva University receive some form of financial aid.   \n",
       "\n",
       "                                                                                                                                                                  predicted_answer  \n",
       "0                                                                The student was awarded a Master of Science degree by the University of Kansas SpeechLanguageHearing Association.  \n",
       "1                                                                                                                       Students get to interact with professors outside of class.  \n",
       "2                                                              Yes, the student community on campus is vibrant, with over 70,000 Yeshiva University alumni and over 70,000 alumni.  \n",
       "3  You can tell me more about the opportunities offered at this university by contacting the Student Council or the specific staff members listed above for their respective roles  \n",
       "4                                                                                                                                Over 80 of students receive financial assistance.  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the predicted answers as a new column in the dataframe\n",
    "test_df_rlhf[args.predicted_result] = answers_rlhf\n",
    "\n",
    "test_predict_rlhf = os.path.join(args.output_dir, args.predict_file)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "test_df_rlhf.to_csv(test_predict_rlhf, index=False)\n",
    "\n",
    "print(len(answers_rlhf))\n",
    "# Load the QApairs.csv file into a pandas dataframe\n",
    "preds_rlhf = pd.read_csv(test_predict_rlhf)\n",
    "\n",
    "preds_rlhf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60521d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge-1</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.451392</td>\n",
       "      <td>0.472653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge-2</td>\n",
       "      <td>0.388525</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.364392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rouge-l</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.436863</td>\n",
       "      <td>0.455598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric  Precision    Recall  F1-Score\n",
       "0  rouge-1   0.529173  0.451392  0.472653\n",
       "1  rouge-2   0.388525  0.357131  0.364392\n",
       "2  rouge-l   0.506200  0.436863  0.455598"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating rogue score for answer 1\n",
    "metrics_df = calculate_rouge_scores(preds_rlhf, args.original_text, args.predicted_result)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56be0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>bert_score_rlhf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the student/faculty ratio at this university?</td>\n",
       "      <td>The student/faculty ratio at Yeshiva University is 7:1.</td>\n",
       "      <td>The student was awarded a Master of Science degree by the University of Kansas SpeechLanguageHearing Association.</td>\n",
       "      <td>0.839125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How often do students get to interact with professors outside of class?</td>\n",
       "      <td>Students at Yeshiva University have ample opportunities to interact with professors outside of class through office hours, research projects, and mentoring programs.</td>\n",
       "      <td>Students get to interact with professors outside of class.</td>\n",
       "      <td>0.913571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How active is the student community on campus?</td>\n",
       "      <td>The student community at Yeshiva University is highly active, with various clubs, organizations, and events that foster a strong sense of community on campus.</td>\n",
       "      <td>Yes, the student community on campus is vibrant, with over 70,000 Yeshiva University alumni and over 70,000 alumni.</td>\n",
       "      <td>0.906102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you tell me more about the extracurricular activities offered at this university?</td>\n",
       "      <td>Yeshiva University offers a wide range of extracurricular activities, including cultural clubs, academic societies, volunteer opportunities, and sports teams.</td>\n",
       "      <td>You can tell me more about the opportunities offered at this university by contacting the Student Council or the specific staff members listed above for their respective roles</td>\n",
       "      <td>0.834625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What percentage of students get financial aid?</td>\n",
       "      <td>Approximately 85% of students at Yeshiva University receive some form of financial aid.</td>\n",
       "      <td>Over 80 of students receive financial assistance.</td>\n",
       "      <td>0.924429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                question  \\\n",
       "0                                  What is the student/faculty ratio at this university?   \n",
       "1                How often do students get to interact with professors outside of class?   \n",
       "2                                         How active is the student community on campus?   \n",
       "3  Can you tell me more about the extracurricular activities offered at this university?   \n",
       "4                                         What percentage of students get financial aid?   \n",
       "\n",
       "                                                                                                                                                                  answer  \\\n",
       "0                                                                                                                The student/faculty ratio at Yeshiva University is 7:1.   \n",
       "1  Students at Yeshiva University have ample opportunities to interact with professors outside of class through office hours, research projects, and mentoring programs.   \n",
       "2         The student community at Yeshiva University is highly active, with various clubs, organizations, and events that foster a strong sense of community on campus.   \n",
       "3         Yeshiva University offers a wide range of extracurricular activities, including cultural clubs, academic societies, volunteer opportunities, and sports teams.   \n",
       "4                                                                                Approximately 85% of students at Yeshiva University receive some form of financial aid.   \n",
       "\n",
       "                                                                                                                                                                  predicted_answer  \\\n",
       "0                                                                The student was awarded a Master of Science degree by the University of Kansas SpeechLanguageHearing Association.   \n",
       "1                                                                                                                       Students get to interact with professors outside of class.   \n",
       "2                                                              Yes, the student community on campus is vibrant, with over 70,000 Yeshiva University alumni and over 70,000 alumni.   \n",
       "3  You can tell me more about the opportunities offered at this university by contacting the Student Council or the specific staff members listed above for their respective roles   \n",
       "4                                                                                                                                Over 80 of students receive financial assistance.   \n",
       "\n",
       "   bert_score_rlhf  \n",
       "0         0.839125  \n",
       "1         0.913571  \n",
       "2         0.906102  \n",
       "3         0.834625  \n",
       "4         0.924429  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore_gpt_rlhf = bertscore.compute(predictions=answers_rlhf, \n",
    "                                           references=test_df_rlhf['answer'].to_list(), \n",
    "                                           lang='en')['f1']\n",
    "\n",
    "test_df_rlhf['bert_score_rlhf'] = bertscore_gpt_rlhf\n",
    "test_df_rlhf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "878c9a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9069235727570482"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_df_rlhf['bert_score_rlhf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405eae78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
